{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Channel', 'Date', 'Message'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Example: Load data from a CSV file\n",
    "df = pd.read_csv('D:/week7 data/telegram_scraped_data.csv')\n",
    "# Display the columns\n",
    "print(df.columns)\n",
    "\n",
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data cleaning completed and saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "\n",
    "# Example data for demonstration\n",
    "data = {\n",
    "    'Channel': ['DoctorsET', 'DoctorsET', 'Lobelia4cosmetics', 'EAHCI'],\n",
    "    'Date': ['2023-01-01', '2023-01-01', '2023-01-02', '2023-01-03'],\n",
    "    'Message': ['Message 1', 'Message 1', 'Message 2', None]\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Data Cleaning Steps\n",
    "# Removing Duplicates\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "# Handling Missing Values\n",
    "df['Message'] = df['Message'].fillna('')  # Using method directly on the column\n",
    "# or\n",
    "# df.fillna({'Message': ''}, inplace=True)  # Using a dictionary\n",
    "\n",
    "# Standardizing Formats\n",
    "df['Date'] = pd.to_datetime(df['Date'])  # Standardizing date format\n",
    "df['Channel'] = df['Channel'].str.lower()  # Converting text to lower case\n",
    "\n",
    "# Data Validation\n",
    "assert df['Date'].notnull().all(), \"Date column contains null values!\"\n",
    "\n",
    "# Storing Cleaned Data\n",
    "# Save as CSV\n",
    "df.to_csv('cleaned_data.csv', index=False)\n",
    "\n",
    "# Save to SQLite\n",
    "conn = sqlite3.connect('data.db')\n",
    "df.to_sql('cleaned_data', conn, if_exists='replace', index=False)\n",
    "\n",
    "print(\"Data cleaning completed and saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned data has been successfully stored in PostgreSQL!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Access the environment variables\n",
    "db_name = os.getenv('DB_NAME')\n",
    "db_user = os.getenv('DB_USER')\n",
    "db_password = os.getenv('DB_PASSWORD')\n",
    "db_host = os.getenv('DB_HOST')\n",
    "db_port = os.getenv('DB_PORT')\n",
    "\n",
    "# Create the database connection string\n",
    "db_url = f\"postgresql://{db_user}:{db_password}@{db_host}:{db_port}/{db_name}\"\n",
    "\n",
    "# Create the SQLAlchemy engine\n",
    "engine = create_engine(db_url)\n",
    "\n",
    "# Load the cleaned data from CSV\n",
    "df = pd.read_csv('D:/week7 data/cleaned_data.csv')\n",
    "\n",
    "# Store DataFrame to PostgreSQL\n",
    "df.to_sql('cleaned_data', con=engine, if_exists='replace', index=False)\n",
    "\n",
    "print(\"Cleaned data has been successfully stored in PostgreSQL!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".ebcli-virtual-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
